{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP tools initialization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINANCIAL_STOP_WORDS = \"\"\"\n",
    "    a about across after afterwards again all almost alone along\n",
    "    already also although always am among amongst amount an and another any anyhow\n",
    "    anyone anything anyway anywhere are as at\n",
    "\n",
    "    be became because become becomes becoming been before beforehand behind\n",
    "    being beside besides between both but by\n",
    "\n",
    "    can cannot ca could\n",
    "\n",
    "    did do does doing done due during\n",
    "\n",
    "    each either else elsewhere empty enough even ever every\n",
    "    everyone everything everywhere except\n",
    "\n",
    "    few for former formerly from full\n",
    "    further\n",
    "\n",
    "    give\n",
    "\n",
    "    had has have he hence her here hereafter hereby herein hereupon hers herself\n",
    "    him himself his how however\n",
    "\n",
    "    i if in indeed into is it its itself\n",
    "\n",
    "    keep\n",
    "\n",
    "    last latter latterly least less\n",
    "\n",
    "    just\n",
    "\n",
    "    made make many may me meanwhile might mine more moreover most mostly much\n",
    "    must my myself\n",
    "\n",
    "    name namely neither never nevertheless next no nobody none noone nor not\n",
    "    nothing now nowhere\n",
    "\n",
    "    of often on once only onto or other others otherwise our ours ourselves\n",
    "    out own\n",
    "\n",
    "    part per perhaps please put\n",
    "\n",
    "    quite\n",
    "\n",
    "    rather re really regarding\n",
    "\n",
    "    same say see seem seemed seeming seems serious several she should show side\n",
    "    since so some somehow someone something sometime sometimes somewhere still such\n",
    "\n",
    "    take than that the their them themselves then thence there thereafter\n",
    "    thereby therefore therein thereupon these they third this those though through\n",
    "    throughout thus to together too toward towards\n",
    "\n",
    "    under until unless upon us used using\n",
    "\n",
    "    various very via was we well were what whatever when whence whenever where\n",
    "    whereafter whereas whereby wherein whereupon wherever whether which while\n",
    "    whither who whoever whole whom whose why will with within without would\n",
    "\n",
    "    yet you your yours yourself yourselves\n",
    "    \"\"\"\n",
    "\n",
    "CONTRACTIONS = [\"n't\", \"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\"]\n",
    "\n",
    "# Expanded list of positive words specific to financial news (preprocessed)\n",
    "POSITIVE_WORDS = [\n",
    "        \"upturn\", \"bullish\", \"rally\", \"advance\", \"expansion\", \"breakthrough\", \n",
    "        \"record high\", \"lucrative\", \"prosperity\", \"fortune\", \"thrive\", \"inflow\", \n",
    "        \"rebound\", \"beat\", \"strategic alliance\", \"upbeat outlook\", \n",
    "        \"milestone\", \"partnership\", \"share buyback\", \"dividend raise\", \"ipo success\", \n",
    "        \"profit surge\", \"rise\", \"soar\", \"bull\", \"raise\", \"generate\", \"noteworthy\",\n",
    "        \"surge\", \"radar\", \"phenomenal\", \"earn\", \"trend stock\"\n",
    "    ]\n",
    "\n",
    "# Expanded list of negative words specific to financial news (preprocessed)\n",
    "NEGATIVE_WORDS = [\n",
    "        \"decline\", \"fall\", \"bearish\", \"plunge\", \"slump\", \"downward\", \"concern\", \n",
    "        \"downturn\", \"outflow\", \"stagnation\", \"layoff\", \"bankruptcy\", \"underperform\", \n",
    "        \"volatility\", \"selloff\", \"sell-off\", \"downgrade\", \"recession fear\", \"shortfall\", \n",
    "        \"plummet\", \"bear market\", \"drop in value\", \"bankruptcy proceeding\", \n",
    "        \"cut forecast\", \"miss estimate\", \"downward pressure\", \"production cut\", \n",
    "        \"regulatory setback\", \"settlement charge\", \"supply chain disruption\", \"bear\",\n",
    "        \"stock down\", \"step down\", \"stock falter\"\n",
    "    ]\n",
    "\n",
    "POSITIVE_PERCENTAGE_WORDS = [\"up\", \"surge\", \"rise\", \"add\", \"soar\", \"jump\", \"climb\", \"rocket\", \"race ahead\", \"yield over\", \"move\"]\n",
    "\n",
    "NEGATIVE_PERCENTAGE_WORDS = [\"down\", \"fall\", \"decline\", \"decrease\", \"plunge\", \"drop\", \"dip\", \"-\", \"slide\"]\n",
    "\n",
    "INPUT_FILE_PATH = r\"C:\\Users\\48531\\Downloads\\Neutral_news2_sample.csv\"\n",
    "\n",
    "OUTPUT_FILE_PATH = r\"C:\\Users\\48531\\Desktop\\SentimentBIIB2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stop_words():\n",
    "\n",
    "    # Converting a string into a list of words and creating a set\n",
    "    stop_words = set(FINANCIAL_STOP_WORDS.split())\n",
    "\n",
    "    # Adding the most common forms of contractions\n",
    "    stop_words.update(CONTRACTIONS)\n",
    "\n",
    "    # Adding contractions with typographic apostrophes\n",
    "    for apostrophe in (\"‘\", \"’\"):\n",
    "        for stopword in CONTRACTIONS:\n",
    "            stop_words.add(stopword.replace(\"'\", apostrophe))\n",
    "    \n",
    "    return stop_words\n",
    "\n",
    "# Using the function\n",
    "stop_words_set = create_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Changing to lowercase letters\n",
    "    text = re.sub(r\"[^-a-zA-Z0-9+%\\s]\", \"\", text)  # Removing unnecessary characters\n",
    "    \n",
    "    doc = nlp(text)  # Tokenization\n",
    "    # Lemmatization and stop-words elimination\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc if token.lemma_ not in stop_words_set])  \n",
    "    \n",
    "    return lemmatized_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment calculation function\n",
    "def calculate_sentiment_vader_custom(raw_news, preprocessed_news):\n",
    "    # Base sentiment score from VADER on raw text (without preprocessing)\n",
    "    sentiment_score = sia.polarity_scores(raw_news)['compound']\n",
    "    \n",
    "    # Adjusting sentiment score based on presence of custom positive and negative words (preprocessed)\n",
    "    sentiment_score += 0.1 * sum(word in preprocessed_news for word in POSITIVE_WORDS)\n",
    "    sentiment_score -= 0.2 * sum(word in preprocessed_news for word in NEGATIVE_WORDS)\n",
    "    \n",
    "    # Checking the context of percentage changes\n",
    "    if any(word in preprocessed_news for word in POSITIVE_PERCENTAGE_WORDS) and '%' in preprocessed_news:\n",
    "        sentiment_score += 0.3\n",
    "    if any(word in preprocessed_news for word in NEGATIVE_PERCENTAGE_WORDS) and '%' in preprocessed_news:\n",
    "        sentiment_score -= 0.4\n",
    "    \n",
    "  # Limiting the result to the range [-1, 1]\n",
    "    return max(min(sentiment_score, 1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "df = pd.read_csv(INPUT_FILE_PATH, delimiter=',', usecols=['news_header', 'news_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying text preprocessing function\n",
    "df['news_header_preprocessed'] = df['news_header'].apply(preprocess_text)\n",
    "\n",
    "# Applying the sentiment analysis function\n",
    "df['sentiment_vader'] = df.apply(lambda row: calculate_sentiment_vader_custom(row['news_header'], row['news_header_preprocessed']), axis=1)\n",
    "\n",
    "# Removing the 'news_header_preprocessed' column after applying the sentiment function\n",
    "df.drop(columns=['news_header_preprocessed'], inplace=True)\n",
    "\n",
    "# Converting news_date to datetime\n",
    "df['news_date'] = pd.to_datetime(df['news_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_header</th>\n",
       "      <th>sentiment_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix (NFLX) Rises Higher Than Market: Key F...</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 ETFs That Have Soared Past the S&amp;P 500 in th...</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia CEO Jensen Huang Describes Why Business...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Zacks Analyst Blog Highlights IBM, Amazon....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spotify Technology and Lamb Weston have been h...</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Stocks Mixed After This Morning's Fed-Friendly...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dow Movers: AAPL, MCD</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2 Stock-Split AI Stocks Up 455% and 1,150% in ...</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Stock Market News for Sep 16, 2024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bear of the Day: Five Below (FIVE)</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          news_header  sentiment_vader\n",
       "0   Netflix (NFLX) Rises Higher Than Market: Key F...              0.1\n",
       "1   3 ETFs That Have Soared Past the S&P 500 in th...              0.1\n",
       "2   Nvidia CEO Jensen Huang Describes Why Business...              0.0\n",
       "3   The Zacks Analyst Blog Highlights IBM, Amazon....              0.0\n",
       "4   Spotify Technology and Lamb Weston have been h...             -0.1\n",
       "..                                                ...              ...\n",
       "95  Stocks Mixed After This Morning's Fed-Friendly...              0.0\n",
       "96                              Dow Movers: AAPL, MCD              0.0\n",
       "97  2 Stock-Split AI Stocks Up 455% and 1,150% in ...             -0.1\n",
       "98                 Stock Market News for Sep 16, 2024              0.0\n",
       "99                 Bear of the Day: Five Below (FIVE)             -0.2\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results to CSV file\n",
    "df.to_csv(OUTPUT_FILE_PATH, sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
